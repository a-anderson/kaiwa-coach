# KaiwaCoach â€“ Implementation Checklist (Derived from PRD v2)

This checklist translates **PRD v2** into concrete, actionable implementation tasks.
It is intended for a **solo developer** working locally on Apple Silicon and is also suitable for use by an LLM coding assistant.

---

## Legend

- â¬œ Not started
- â³ In progress
- âœ… Done
- ğŸ” Revisit later

---

## 0. Project Setup (Foundational)

âœ… Create repository structure per TDD  
âœ… Set Python version to **3.11.x (tested baseline)**  
âœ… Create virtual environment
âœ… Run setup script to install UniDic assets (`python -m unidic download`)  
âœ… Add dependency management (`pyproject.toml` or `requirements.txt`) including:

- `mlx`
- `mlx-lm`
- MLX Whisper package
- MLX Kokoro package
- `gradio`
- `pydantic`
- `soundfile` / `scipy`
- stdlib `sqlite3`

âœ… Add `.gitignore` (models, session audio cache, DB files)  
âœ… Add `README.md` referencing PRD v2 and TDD

---

## 1. Configuration Layer

âœ… Implement `settings.py`  
âœ… Define defaults:

- Session language (`ja` / `fr` / `en`)
- ASR model ID
- LLM model ID (default 8-bit)
- TTS model ID
- Storage root path
- TTS voice and speed
- Per-role token limits

âœ… Support environment variable overrides  
âœ… Validate configuration at startup

---

## 2. Storage Layer

### 2.1 Database Schema

âœ… Create `schema.sql`  
âœ… Tables:

- `conversations`
- `user_turns`
- `assistant_turns`
- `corrections`
- `artifacts`

âœ… Add schema versioning

---

### 2.2 SQLite Access

âœ… Implement `storage/db.py`  
âœ… Enforce single-writer queue  
âœ… Ensure all writes go through one connection  
âœ… Safe concurrent reads for Gradio callbacks

---

### 2.3 Audio Cache (Session-only)

âœ… Implement `storage/blobs.py` for **session-only** audio cache  
âœ… Deterministic paths (session temp dir):

- per conversation
- per turn
- hash-based filenames

âœ… WAV save/load helpers  
âœ… Enforce sample rate consistency  
âœ… Delete session audio cache on app exit

---

### 2.4 Conversation Persistence (Across Restarts)

âœ… Auto-persist chat turns to SQLite (already writing user/assistant/corrections)  
âœ… Store conversation metadata (language, model IDs) for replay  
âœ… Add schema notes for forward compatibility  
âœ… Add conversation index query (title, last updated, language)  
âœ… Add summary/preview field for list view  
âœ… Add fetch-by-id API to load full conversation  
âœ… Define history formatting/truncation for resumed chats  
âœ… Support resume flow: load history + continue new turns  
âœ… Add delete/export hooks (optional, post-MVP if needed)

---

## 3. ASR Module

âœ… Implement `models/asr_whisper.py`  
âœ… Load ASR model via `settings.py` (default set in `config/models.py`)  
âœ… Force language per session  
ğŸ” Preserve English words in mixed-language utterances

âœ… Return:

- transcript
- ASR metadata

âœ… Cache ASR results by audio hash (session-only)

---

## 4. LLM Core Wrapper

### 4.1 Base Wrapper

âœ… Implement `models/llm_qwen.py`  
âœ… Load LLM via `settings.py` (default set in `config/models.py`)  
âœ… Integrate MLX-LM backend in `models/llm_qwen.py`  
ğŸ” Support optional BF16 mode  
âœ… Use MLX tokenizer for prompt token counting  
âœ… Enforce:

- max context tokens
- per-call max tokens

âœ… Capture timing and metadata

---

### 4.2 JSON Schema Enforcement

âœ… Implement first-valid-object JSON extraction
âœ… Ignore/log trailing content

âœ… Define Pydantic schemas for:

- Conversation reply
- Error detection
- Corrected sentence
- Native reformulation
- Explanation
- JP TTS normalisation

âœ… Strict JSON parsing  
âœ… One retry max via repair prompt  
âœ… Safe fallback on failure

---

## 5. Prompt Management

âœ… Create `prompts/` directory  
âœ… Add prompt files:

- `conversation.md`
- `detect_errors.md`
- `correct_sentence.md`
- `native_rewrite.md`
- `explain.md`
- `jp_tts_normalise.md`
- `repair_json.md`

âœ… Implement prompt loader:

- markdown read
- variable interpolation
- SHA256 hash generation

---

## 6. Japanese TTS Normalisation

### 6.1 Protected Spans (`textnorm/protected_spans.py`)

âœ… Implement masking for:

- URLs
- file paths
- emails
- code blocks
- markdown links

---

### 6.2 Katakana Conversion (`textnorm/jp_katakana.py`)

âœ… Implement LLM-based rewrite (temp = 0)  
âœ… Rewrite only non-Japanese spans
âœ… Implement LLM rewrite function for katakana conversion (uses `jp_tts_normalise.md`)

---

### 6.3 Invariant Mitigation Hooks (`textnorm/invariants.py`)

âœ… Detect Japanese substrings  
âœ… Verify byte-identical preservation  
âœ… Fallback + log on violation

---

### 6.4 Punctuation / Pause Normalisation (`textnorm/tts_punctuation.py`)

âœ… Normalize sentence breaks  
âœ… Normalize repeated punctuation  
âœ… Insert pauses for Kokoro

---

## 7. TTS Module

âœ… Implement `models/tts_kokoro.py`  
âœ… Load TTS model via `settings.py` (default set in `config/models.py`)  
âœ… Generate WAV output  
âœ… Cache TTS by `(text, voice, speed)` (session-only)

---

## 8. Conversation Orchestrator

âœ… Implement `orchestrator.py`

### Text Turn Flow

âœ… Persist `UserTurn`  
âœ… Generate assistant reply  
âœ… Persist `AssistantTurn`  
âœ… Generate corrections  
âœ… Generate native reformulation  
âœ… Persist `Correction`  
âœ… Normalise for TTS (JP)  
âœ… Generate TTS  
âœ… Cache audio for active session only (do not persist)

---

### Audio Turn Flow

âœ… Cache raw audio for active session only  
âœ… Run ASR  
âœ… Persist transcript  
âœ… Continue text flow

---

### Orchestrator Rules

âœ… Schema validation at every step  
âœ… Persist intermediates before side-effects  
âœ… Graceful degradation on failure  
âœ… Store prompt hash per LLM call (orchestrator)  
âœ… Pass session language into TTS synthesis by default  
âœ… Call katakana LLM rewrite step in the TTS normalisation pipeline

---

## 9. Gradio UI

âœ… Implement `app.py`  
âœ… UI elements:

- Chat transcript
- Text input
- Microphone input
- Send button
- Per-turn audio playback (session cache, user + assistant)
- Corrections panel

âœ… Wire orchestrator with ASR + audio cache in `app.py` / UI setup  
âœ… Session reset support  
âœ… Safe interaction with DB queue

---

### 9.1 Conversation History UI

âœ… Conversation list panel (title, last updated, language)  
âœ… Conversation preview (summary or last assistant reply)  
âœ… Select conversation â†’ load transcript into chat  
âœ… Continue conversation â†’ append new turns  
âœ… New conversation action (clear state + start fresh)  
âœ… Delete conversation (optional; can be post-MVP)  
âœ… Delete all history (bulk delete)  
âœ… Empty state handling (no conversations yet)  
ğŸ” Loading/error states for list and selection

---

## 10. Caching and Performance

âœ… ASR cache (session-only)  
âœ… LLM output cache  
âœ… TTS cache (session-only)

âœ… Per-step timing logs

---

### LLM UX Performance (Revisit Later)

âœ… Improve turn-to-turn response quality

- Reduce repetition across turns
- Enforce response language
- Avoid generic filler
- Ground responses in conversation history
- Keep replies concise unless user asks for more

âœ… Reduce assistant response latency after user submission  
âœ… Reduce end-to-end load time between input and reply (model warmup, caching, prompt prep)
âœ… Reduce total turn time (including correction + TTS overhead)
âœ… Enforce prompt strictness at decode level (stop sequences / tighter schema enforcement)

---

## 11. Testing

### Schema Tests

âœ… Validate all LLM schemas  
âœ… Test repair prompt

### Model Integration (Slow)

âœ… ASR integration test (real model, marked `@pytest.mark.slow`)  
âœ… Core LLM integration test (real model, marked `@pytest.mark.slow`)  
âœ… TTS integration test (real model, marked `@pytest.mark.slow`)

---

### Japanese Normalisation Golden Tests (High Priority)

âœ… Create JP/EN mixed fixtures  
âœ… Assert katakana conversion or invariant fallback

---

### Storage Tests

âœ… DB insert/read round-trip  
âœ… Session audio cache save/load tests

---

## 12. Resource and Stability

âœ… Enforce context truncation

- Add real token counting (use model tokenizer)
- Trim oldest conversation history first
- Preserve latest user turn and required fields
  âœ… Enforce token caps per role  
  ğŸ” Periodic memory logging

âœ… Manual session reset control

---

## 13. MVP Exit Criteria

âœ… Spoken JP conversation works end-to-end  
âœ… Corrections and native phrasing displayed  
âœ… Kokoro pronounces mixed JP/EN correctly  
âœ… Conversations persist across restarts (text)  
âœ… Stable operation within ~22â€“26 GB RAM

---

## 14. Post-MVP (Optional)

âœ… Add support for other languages
ğŸ” Correction text persists across restarts
ğŸ” Pronunciation scoring  
ğŸ” Download option for message audio
ğŸ” Audio regeneration (single turn + full conversation)
ğŸ” ASR confidence-based UX  
ğŸ” Shadowing mode  
ğŸ” Anki export  
ğŸ” Desktop packaging
âœ… Toggle to disable corrections (speed-focused mode)
ğŸ” Evaluate smaller LLM variants (e.g., 4-bit) for latency
